{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b38c790c-cdce-493b-9685-e25482a937fd",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuração do ambiente:\n",
      "Python: 3.10.0\n",
      "Executável: C:\\Users\\Gabriel\\Documents\\ml-data-studying-projects\\venv_spark\\Scripts\\python.exe\n",
      "Bibliotecas importadas\n",
      "Spark 4.0.1 iniciado\n",
      "App: ETL_COVID_to_SQL\n",
      "\n",
      "Fase 1: Extração\n",
      "Baixando de: https://raw.githubusercontent.com/wcota/covid19br/master/cases-brazil-cities.csv\n",
      "Arquivo baixado: 0.54 MB\n",
      "\n",
      "Lendo CSV com Spark...\n",
      "Registros: 5,596\n",
      "Colunas: 14\n",
      "\n",
      "Primeiras linhas:\n",
      "+-------+-----+----------------------+-------+------+----------+---------------------------+-------------------------------+--------------------+-------+----------+--------+---------+--------------+\n",
      "|country|state|city                  |ibgeID |deaths|totalCases|deaths_per_100k_inhabitants|totalCases_per_100k_inhabitants|deaths_by_totalCases|_source|date      |newCases|newDeaths|last_info_date|\n",
      "+-------+-----+----------------------+-------+------+----------+---------------------------+-------------------------------+--------------------+-------+----------+--------+---------+--------------+\n",
      "|Brazil |GO   |Abadia de Goiás/GO    |5200050|50    |4074      |545.97074                  |44485.69557                    |0.01227             |MS     |2023-03-18|5       |0        |2023-03-18    |\n",
      "|Brazil |MG   |Abadia dos Dourados/MG|3100104|21    |1943      |299.0601                   |27670.17944                    |0.01081             |MS     |2023-03-18|0       |0        |2023-03-18    |\n",
      "|Brazil |GO   |Abadiânia/GO          |5200100|55    |2218      |263.4983                   |10626.16778                    |0.0248              |MS     |2023-03-18|-1      |0        |2023-03-18    |\n",
      "|Brazil |PA   |Abaetetuba/PA         |1500107|244   |12009     |152.08272                  |7485.08779                     |0.02032             |MS     |2023-03-18|13      |0        |2023-03-18    |\n",
      "|Brazil |MG   |Abaeté/MG             |3100203|51    |4279      |219.23226                  |18394.01625                    |0.01192             |MS     |2023-03-18|0       |0        |2023-03-18    |\n",
      "+-------+-----+----------------------+-------+------+----------+---------------------------+-------------------------------+--------------------+-------+----------+--------+---------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Schema dos dados:\n",
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- ibgeID: integer (nullable = true)\n",
      " |-- deaths: integer (nullable = true)\n",
      " |-- totalCases: integer (nullable = true)\n",
      " |-- deaths_per_100k_inhabitants: double (nullable = true)\n",
      " |-- totalCases_per_100k_inhabitants: double (nullable = true)\n",
      " |-- deaths_by_totalCases: double (nullable = true)\n",
      " |-- _source: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- newCases: integer (nullable = true)\n",
      " |-- newDeaths: integer (nullable = true)\n",
      " |-- last_info_date: date (nullable = true)\n",
      "\n",
      "\n",
      "Colunas disponíveis:\n",
      "1. country\n",
      "2. state\n",
      "3. city\n",
      "4. ibgeID\n",
      "5. deaths\n",
      "6. totalCases\n",
      "7. deaths_per_100k_inhabitants\n",
      "8. totalCases_per_100k_inhabitants\n",
      "9. deaths_by_totalCases\n",
      "10. _source\n",
      "11. date\n",
      "12. newCases\n",
      "13. newDeaths\n",
      "14. last_info_date\n",
      "\n",
      "Estatísticas:\n",
      "+-------+-------+-----+------------------+------------------+------------------+------------------+---------------------------+-------------------------------+--------------------+-------+-----------------+------------------+\n",
      "|summary|country|state|              city|            ibgeID|            deaths|        totalCases|deaths_per_100k_inhabitants|totalCases_per_100k_inhabitants|deaths_by_totalCases|_source|         newCases|         newDeaths|\n",
      "+-------+-------+-----+------------------+------------------+------------------+------------------+---------------------------+-------------------------------+--------------------+-------+-----------------+------------------+\n",
      "|  count|   5596| 5596|              5596|              5596|              5596|              5596|                       5596|                           5596|                5596|   5596|             5596|              5596|\n",
      "|   mean|   NULL| NULL|              NULL| 3238474.146890636|124.96604717655468| 6627.147962830593|         264.41535558970577|             18658.703739522953|0.016964592566118687|   NULL|              0.0|               0.0|\n",
      "| stddev|   NULL| NULL|              NULL|1007225.7318231501|  916.348086215888|33093.529677000035|         239.98985344333795|             11756.863054587982|0.012580441630968863|   NULL|352.5162297330446|2.1629754768178593|\n",
      "|    min| Brazil|   AC|Abadia de Goiás/GO|                11|              -258|            -37026|                   -0.69505|                      -197.4378|                 0.0|     GI|           -17239|              -121|\n",
      "|    max| Brazil|   TO|           Óleo/SP|           5300108|             44671|           1316242|                14039.97865|                   337540.77941|              0.3125|     MS|            10164|                52|\n",
      "+-------+-------+-----+------------------+------------------+------------------+------------------+---------------------------+-------------------------------+--------------------+-------+-----------------+------------------+\n",
      "\n",
      "\n",
      "Valores nulos por coluna:\n",
      "+-------+-----+----+------+------+----------+---------------------------+-------------------------------+--------------------+-------+----+--------+---------+--------------+\n",
      "|country|state|city|ibgeID|deaths|totalCases|deaths_per_100k_inhabitants|totalCases_per_100k_inhabitants|deaths_by_totalCases|_source|date|newCases|newDeaths|last_info_date|\n",
      "+-------+-----+----+------+------+----------+---------------------------+-------------------------------+--------------------+-------+----+--------+---------+--------------+\n",
      "|      0|    0|   0|     0|     0|         0|                          0|                              0|                   0|      0|   0|       0|        0|             0|\n",
      "+-------+-----+----+------+------+----------+---------------------------+-------------------------------+--------------------+-------+----+--------+---------+--------------+\n",
      "\n",
      "\n",
      "Fase 2: Transformação\n",
      "Colunas selecionadas: ['date', 'state', 'city', 'totalCases', 'newCases', 'deaths', 'newDeaths']\n",
      "\n",
      "Removendo valores nulos...\n",
      "Removidos: 0\n",
      "Restantes: 5,596\n",
      "\n",
      "Removendo duplicatas...\n",
      "Duplicatas removidas: 0\n",
      "\n",
      "Convertendo tipos de dados...\n",
      "\n",
      "Adicionando colunas calculadas...\n",
      "\n",
      "Renomeando colunas...\n",
      "Transformação concluída\n",
      "\n",
      "Schema final:\n",
      "root\n",
      " |-- data: date (nullable = true)\n",
      " |-- estado: string (nullable = true)\n",
      " |-- cidade: string (nullable = true)\n",
      " |-- casos_totais: integer (nullable = true)\n",
      " |-- casos_novos: integer (nullable = true)\n",
      " |-- obitos_totais: integer (nullable = true)\n",
      " |-- obitos_novos: integer (nullable = true)\n",
      " |-- ano: integer (nullable = true)\n",
      " |-- mes: integer (nullable = true)\n",
      " |-- data_carga: timestamp (nullable = false)\n",
      "\n",
      "\n",
      "Amostra dos dados:\n",
      "+----------+------+--------------------+------------+-----------+-------------+------------+----+---+--------------------+\n",
      "|      data|estado|              cidade|casos_totais|casos_novos|obitos_totais|obitos_novos| ano|mes|          data_carga|\n",
      "+----------+------+--------------------+------------+-----------+-------------+------------+----+---+--------------------+\n",
      "|2023-03-18|    SE|          Aracaju/SE|      169414|         32|         2616|           0|2023|  3|2025-10-15 21:30:...|\n",
      "|2023-03-18|    PA|           Bujaru/PA|        2081|          4|           43|           0|2023|  3|2025-10-15 21:30:...|\n",
      "|2023-03-18|    MT|CASO SEM LOCALIZA...|           0|          0|            0|           0|2023|  3|2025-10-15 21:30:...|\n",
      "|2023-03-18|    RS|    Cacique Doble/RS|        1443|          0|           15|           0|2023|  3|2025-10-15 21:30:...|\n",
      "|2023-03-18|    RS|    Caxias do Sul/RS|      168401|        255|         1701|           0|2023|  3|2025-10-15 21:30:...|\n",
      "|2023-03-18|    SP|Cristais Paulista/SP|        1307|          0|           20|           0|2023|  3|2025-10-15 21:30:...|\n",
      "|2023-03-18|    SP|           Fernão/SP|         747|          0|            5|           0|2023|  3|2025-10-15 21:30:...|\n",
      "|2023-03-18|    MG|       Fervedouro/MG|        1655|          0|           20|           0|2023|  3|2025-10-15 21:30:...|\n",
      "|2023-03-18|    BA|            Ipirá/BA|        3329|          1|           80|           0|2023|  3|2025-10-15 21:30:...|\n",
      "|2023-03-18|    PE|         Itapetim/PE|        2879|          1|           39|           0|2023|  3|2025-10-15 21:30:...|\n",
      "+----------+------+--------------------+------------+-----------+-------------+------------+----+---+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Estatísticas finais:\n",
      "+-------+-----------------+-----------------+------------------+------------------+\n",
      "|summary|     casos_totais|      casos_novos|     obitos_totais|      obitos_novos|\n",
      "+-------+-----------------+-----------------+------------------+------------------+\n",
      "|  count|             5596|             5596|              5596|              5596|\n",
      "|   mean|6627.147962830593|              0.0|124.96604717655468|               0.0|\n",
      "| stddev|33093.52967699999|352.5162297330447| 916.3480862158888|2.1629754768178606|\n",
      "|    min|           -37026|           -17239|              -258|              -121|\n",
      "|    max|          1316242|            10164|             44671|                52|\n",
      "+-------+-----------------+-----------------+------------------+------------------+\n",
      "\n",
      "\n",
      "Top 10 Estados com mais casos:\n",
      "+------+-----------+------------+\n",
      "|estado|total_casos|total_obitos|\n",
      "+------+-----------+------------+\n",
      "|    SP|    6469442|      179039|\n",
      "|    MG|    4189760|       65507|\n",
      "|    RS|    2962414|       41921|\n",
      "|    PR|    2920177|       46022|\n",
      "|    RJ|    2754359|       76852|\n",
      "|    SC|    1986447|       22703|\n",
      "|    GO|    1900459|       28041|\n",
      "|    BA|    1792572|       31459|\n",
      "|    CE|    1453417|       28157|\n",
      "|    ES|    1323595|       15041|\n",
      "+------+-----------+------------+\n",
      "\n",
      "\n",
      "Casos por ano:\n",
      "+----+---------+----------+\n",
      "| ano|casos_ano|obitos_ano|\n",
      "+----+---------+----------+\n",
      "|2023|        0|         0|\n",
      "+----+---------+----------+\n",
      "\n",
      "\n",
      "Dados mais recentes:\n",
      "+----------+------+--------------------+------------+-----------+-------------+------------+----+---+--------------------+\n",
      "|      data|estado|              cidade|casos_totais|casos_novos|obitos_totais|obitos_novos| ano|mes|          data_carga|\n",
      "+----------+------+--------------------+------------+-----------+-------------+------------+----+---+--------------------+\n",
      "|2023-03-18|    SE|          Aracaju/SE|      169414|         32|         2616|           0|2023|  3|2025-10-15 21:30:...|\n",
      "|2023-03-18|    PA|           Bujaru/PA|        2081|          4|           43|           0|2023|  3|2025-10-15 21:30:...|\n",
      "|2023-03-18|    MT|CASO SEM LOCALIZA...|           0|          0|            0|           0|2023|  3|2025-10-15 21:30:...|\n",
      "|2023-03-18|    RS|    Cacique Doble/RS|        1443|          0|           15|           0|2023|  3|2025-10-15 21:30:...|\n",
      "|2023-03-18|    RS|    Caxias do Sul/RS|      168401|        255|         1701|           0|2023|  3|2025-10-15 21:30:...|\n",
      "+----------+------+--------------------+------------+-----------+-------------+------------+----+---+--------------------+\n",
      "\n",
      "\n",
      "Salvando dados processados...\n",
      "CSV salvo: ../data/processed/covid19_brazil_clean.csv\n",
      "Registros: 5,596\n",
      "Parquet salvo: ../data/processed/covid19_brazil_clean.parquet\n",
      "\n",
      "Fase 3: Carregamento\n",
      "\n",
      "Criando amostra para SQL Server...\n",
      "Amostra: 1,000 registros\n",
      "+----------+------+--------------------+------------+-----------+-------------+------------+----+---+--------------------+\n",
      "|      data|estado|              cidade|casos_totais|casos_novos|obitos_totais|obitos_novos| ano|mes|          data_carga|\n",
      "+----------+------+--------------------+------------+-----------+-------------+------------+----+---+--------------------+\n",
      "|2023-03-18|    SE|          Aracaju/SE|      169414|         32|         2616|           0|2023|  3|2025-10-15 21:30:...|\n",
      "|2023-03-18|    PA|           Bujaru/PA|        2081|          4|           43|           0|2023|  3|2025-10-15 21:30:...|\n",
      "|2023-03-18|    MT|CASO SEM LOCALIZA...|           0|          0|            0|           0|2023|  3|2025-10-15 21:30:...|\n",
      "|2023-03-18|    RS|    Cacique Doble/RS|        1443|          0|           15|           0|2023|  3|2025-10-15 21:30:...|\n",
      "|2023-03-18|    RS|    Caxias do Sul/RS|      168401|        255|         1701|           0|2023|  3|2025-10-15 21:30:...|\n",
      "+----------+------+--------------------+------------+-----------+-------------+------------+----+---+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Gerando script SQL...\n",
      "Script SQL salvo: ../sql/create_table_covid19.sql\n",
      "\n",
      "Gerando comandos INSERT...\n",
      "Script INSERT salvo: ../sql/insert_covid19_sample.sql\n",
      "Total de INSERTs: 10\n",
      "\n",
      "Exemplo de INSERT:\n",
      "-- Inserir dados de exemplo\n",
      "USE datalake_local;\n",
      "GO\n",
      "\n",
      "INSERT INTO dbo.covid19_brazil (data, estado, cidade, casos_totais, casos_novos, obitos_totais, obitos_novos, ano, mes) VALUES ('2023-03-18', 'SE', 'Aracaju/SE', 169414, 32, 2616, 0, 2023, 3);\n",
      "INSERT INTO dbo.covid19_brazil (data, estado, cidade, casos_totais, casos_novos, obitos_totais, obitos_novos, ano, mes) VALUES ('2023-03-18', 'PA', 'Bujaru/PA', 2081, 4, 43, 0, 2023, 3);\n",
      "INSERT INTO dbo.covid19_brazil (data, estado, cidade, casos_totais, casos_novos, obitos_totais, obitos_novos, ano, mes) VALUES ('2023-03-18', 'MT', 'CASO SEM LOCALIZAÇÃO DEFINIDA/MT', 0, 0, 0, 0, 2023, 3);\n",
      "\n",
      "\n",
      "============================================================\n",
      "RESUMO DO PIPELINE ETL\n",
      "============================================================\n",
      "\n",
      "EXTRACT:\n",
      "  Fonte: COVID-19 Brasil (GitHub)\n",
      "  Registros originais: 5,596\n",
      "\n",
      "TRANSFORM:\n",
      "  Colunas: 10\n",
      "  Registros limpos: 5,596\n",
      "\n",
      "LOAD:\n",
      "  CSV: ../data/processed/covid19_brazil_clean.csv\n",
      "  Parquet: ../data/processed/covid19_brazil_clean.parquet\n",
      "  SQL: ../sql/create_table_covid19.sql\n",
      "  Inserts: ../sql/insert_covid19_sample.sql\n",
      "\n",
      "============================================================\n",
      "Pipeline concluído\n",
      "============================================================\n",
      "\n",
      "Spark Session ativa para análises adicionais\n"
     ]
    }
   ],
   "source": [
    "# Pipeline ETL - COVID-19 Brasil → SQL Server\n",
    "# 16/10/2025\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Configurações Spark\n",
    "python_path = sys.executable\n",
    "os.environ['PYSPARK_PYTHON'] = python_path\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = python_path\n",
    "os.environ['SPARK_LOCAL_HOSTNAME'] = 'localhost'\n",
    "\n",
    "print(\"Configuração do ambiente:\")\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"Executável: {python_path}\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "print(\"Bibliotecas importadas\")\n",
    "\n",
    "# ============================================\n",
    "\n",
    "# Criando Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETL_COVID_to_SQL\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.driver.host\", \"localhost\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark {spark.version} iniciado\")\n",
    "print(f\"App: {spark.sparkContext.appName}\")\n",
    "\n",
    "# ============================================\n",
    "\n",
    "# EXTRACT - Baixando dados públicos\n",
    "print(\"\\nFase 1: Extração\")\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/wcota/covid19br/master/cases-brazil-cities.csv\"\n",
    "os.makedirs(\"../data/raw\", exist_ok=True)\n",
    "raw_file = \"../data/raw/covid19_brazil_raw.csv\"\n",
    "\n",
    "print(f\"Baixando de: {url}\")\n",
    "try:\n",
    "    urllib.request.urlretrieve(url, raw_file)\n",
    "    file_size = os.path.getsize(raw_file) / (1024 * 1024)\n",
    "    print(f\"Arquivo baixado: {file_size:.2f} MB\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao baixar: {e}\")\n",
    "\n",
    "# ============================================\n",
    "\n",
    "# Lendo CSV\n",
    "print(\"\\nLendo CSV com Spark...\")\n",
    "\n",
    "df_raw = spark.read.csv(\n",
    "    raw_file,\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    sep=\",\"\n",
    ")\n",
    "\n",
    "print(f\"Registros: {df_raw.count():,}\")\n",
    "print(f\"Colunas: {len(df_raw.columns)}\")\n",
    "\n",
    "print(\"\\nPrimeiras linhas:\")\n",
    "df_raw.show(5, truncate=False)\n",
    "\n",
    "# ============================================\n",
    "\n",
    "# Análise exploratória\n",
    "print(\"\\nSchema dos dados:\")\n",
    "df_raw.printSchema()\n",
    "\n",
    "print(\"\\nColunas disponíveis:\")\n",
    "for i, col in enumerate(df_raw.columns, 1):\n",
    "    print(f\"{i}. {col}\")\n",
    "\n",
    "print(\"\\nEstatísticas:\")\n",
    "df_raw.describe().show()\n",
    "\n",
    "# Valores nulos\n",
    "print(\"\\nValores nulos por coluna:\")\n",
    "from pyspark.sql.functions import col, sum as spark_sum, when\n",
    "\n",
    "null_counts = df_raw.select([\n",
    "    spark_sum(when(col(c).isNull(), 1).otherwise(0)).alias(c)\n",
    "    for c in df_raw.columns\n",
    "])\n",
    "null_counts.show()\n",
    "\n",
    "# ============================================\n",
    "\n",
    "# TRANSFORM - Limpeza e transformação\n",
    "print(\"\\nFase 2: Transformação\")\n",
    "\n",
    "# Selecionar colunas relevantes\n",
    "colunas_interesse = [\n",
    "    'date', 'state', 'city', 'totalCases', \n",
    "    'newCases', 'deaths', 'newDeaths'\n",
    "]\n",
    "\n",
    "colunas_disponiveis = [c for c in colunas_interesse if c in df_raw.columns]\n",
    "print(f\"Colunas selecionadas: {colunas_disponiveis}\")\n",
    "\n",
    "df_clean = df_raw.select(colunas_disponiveis)\n",
    "\n",
    "# Remover nulos\n",
    "print(\"\\nRemovendo valores nulos...\")\n",
    "registros_antes = df_clean.count()\n",
    "df_clean = df_clean.dropna(subset=['date', 'state', 'city'])\n",
    "registros_depois = df_clean.count()\n",
    "print(f\"Removidos: {registros_antes - registros_depois:,}\")\n",
    "print(f\"Restantes: {registros_depois:,}\")\n",
    "\n",
    "# Remover duplicatas\n",
    "print(\"\\nRemovendo duplicatas...\")\n",
    "registros_antes = df_clean.count()\n",
    "df_clean = df_clean.dropDuplicates(['date', 'state', 'city'])\n",
    "registros_depois = df_clean.count()\n",
    "print(f\"Duplicatas removidas: {registros_antes - registros_depois:,}\")\n",
    "\n",
    "# Converter tipos\n",
    "print(\"\\nConvertendo tipos de dados...\")\n",
    "df_clean = df_clean.withColumn('date', to_date(col('date'), 'yyyy-MM-dd'))\n",
    "df_clean = df_clean.withColumn('totalCases', col('totalCases').cast('integer'))\n",
    "df_clean = df_clean.withColumn('newCases', col('newCases').cast('integer'))\n",
    "df_clean = df_clean.withColumn('deaths', col('deaths').cast('integer'))\n",
    "df_clean = df_clean.withColumn('newDeaths', col('newDeaths').cast('integer'))\n",
    "\n",
    "# Adicionar colunas calculadas\n",
    "print(\"\\nAdicionando colunas calculadas...\")\n",
    "df_clean = df_clean.withColumn('year', year(col('date')))\n",
    "df_clean = df_clean.withColumn('month', month(col('date')))\n",
    "df_clean = df_clean.withColumn('data_carga', current_timestamp())\n",
    "\n",
    "# Renomear para português\n",
    "print(\"\\nRenomeando colunas...\")\n",
    "df_clean = df_clean \\\n",
    "    .withColumnRenamed('date', 'data') \\\n",
    "    .withColumnRenamed('state', 'estado') \\\n",
    "    .withColumnRenamed('city', 'cidade') \\\n",
    "    .withColumnRenamed('totalCases', 'casos_totais') \\\n",
    "    .withColumnRenamed('newCases', 'casos_novos') \\\n",
    "    .withColumnRenamed('deaths', 'obitos_totais') \\\n",
    "    .withColumnRenamed('newDeaths', 'obitos_novos') \\\n",
    "    .withColumnRenamed('year', 'ano') \\\n",
    "    .withColumnRenamed('month', 'mes')\n",
    "\n",
    "print(\"Transformação concluída\")\n",
    "\n",
    "# ============================================\n",
    "\n",
    "# Visualizar dados limpos\n",
    "print(\"\\nSchema final:\")\n",
    "df_clean.printSchema()\n",
    "\n",
    "print(\"\\nAmostra dos dados:\")\n",
    "df_clean.show(10)\n",
    "\n",
    "print(\"\\nEstatísticas finais:\")\n",
    "df_clean.select('casos_totais', 'casos_novos', 'obitos_totais', 'obitos_novos').describe().show()\n",
    "\n",
    "# ============================================\n",
    "\n",
    "# Análises básicas\n",
    "print(\"\\nTop 10 Estados com mais casos:\")\n",
    "df_clean.groupBy('estado') \\\n",
    "    .agg(\n",
    "        sum('casos_totais').alias('total_casos'),\n",
    "        sum('obitos_totais').alias('total_obitos')\n",
    "    ) \\\n",
    "    .orderBy(col('total_casos').desc()) \\\n",
    "    .limit(10) \\\n",
    "    .show()\n",
    "\n",
    "print(\"\\nCasos por ano:\")\n",
    "df_clean.groupBy('ano') \\\n",
    "    .agg(\n",
    "        sum('casos_novos').alias('casos_ano'),\n",
    "        sum('obitos_novos').alias('obitos_ano')\n",
    "    ) \\\n",
    "    .orderBy('ano') \\\n",
    "    .show()\n",
    "\n",
    "print(\"\\nDados mais recentes:\")\n",
    "df_clean.orderBy(col('data').desc()).limit(5).show()\n",
    "\n",
    "# ============================================\n",
    "\n",
    "# Salvar dados limpos\n",
    "print(\"\\nSalvando dados processados...\")\n",
    "\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "# CSV\n",
    "processed_file = \"../data/processed/covid19_brazil_clean.csv\"\n",
    "df_clean_pandas = df_clean.toPandas()\n",
    "df_clean_pandas.to_csv(processed_file, index=False)\n",
    "print(f\"CSV salvo: {processed_file}\")\n",
    "print(f\"Registros: {len(df_clean_pandas):,}\")\n",
    "\n",
    "# Parquet\n",
    "parquet_path = \"../data/processed/covid19_brazil_clean.parquet\"\n",
    "df_clean_pandas.to_parquet(parquet_path, index=False)\n",
    "print(f\"Parquet salvo: {parquet_path}\")\n",
    "\n",
    "# ============================================\n",
    "\n",
    "# LOAD - Preparar para SQL Server\n",
    "print(\"\\nFase 3: Carregamento\")\n",
    "\n",
    "# Criar amostra menor\n",
    "print(\"\\nCriando amostra para SQL Server...\")\n",
    "df_sample = df_clean.orderBy(col('data').desc()).limit(1000)\n",
    "\n",
    "print(f\"Amostra: {df_sample.count():,} registros\")\n",
    "df_sample.show(5)\n",
    "\n",
    "# ============================================\n",
    "\n",
    "# Criar script SQL\n",
    "print(\"\\nGerando script SQL...\")\n",
    "\n",
    "sql_script = \"\"\"-- Script de criação da tabela COVID-19\n",
    "-- Gerado automaticamente pelo pipeline ETL\n",
    "-- Data: 16/10/2025\n",
    "\n",
    "USE datalake_local;\n",
    "GO\n",
    "\n",
    "-- Limpar tabela se existir\n",
    "IF OBJECT_ID('dbo.covid19_brazil', 'U') IS NOT NULL\n",
    "    DROP TABLE dbo.covid19_brazil;\n",
    "GO\n",
    "\n",
    "-- Criar tabela\n",
    "CREATE TABLE dbo.covid19_brazil (\n",
    "    data DATE NOT NULL,\n",
    "    estado VARCHAR(2),\n",
    "    cidade VARCHAR(200),\n",
    "    casos_totais INT,\n",
    "    casos_novos INT,\n",
    "    obitos_totais INT,\n",
    "    obitos_novos INT,\n",
    "    ano INT,\n",
    "    mes INT,\n",
    "    data_carga DATETIME DEFAULT GETDATE()\n",
    ");\n",
    "GO\n",
    "\n",
    "-- Índices para performance\n",
    "CREATE INDEX idx_data ON dbo.covid19_brazil(data);\n",
    "CREATE INDEX idx_estado ON dbo.covid19_brazil(estado);\n",
    "CREATE INDEX idx_cidade ON dbo.covid19_brazil(cidade);\n",
    "GO\n",
    "\n",
    "PRINT 'Tabela covid19_brazil criada';\n",
    "GO\n",
    "\"\"\"\n",
    "\n",
    "sql_file = \"../sql/create_table_covid19.sql\"\n",
    "os.makedirs(\"../sql\", exist_ok=True)\n",
    "with open(sql_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(sql_script)\n",
    "\n",
    "print(f\"Script SQL salvo: {sql_file}\")\n",
    "\n",
    "# ============================================\n",
    "\n",
    "# Gerar INSERT SQL\n",
    "print(\"\\nGerando comandos INSERT...\")\n",
    "\n",
    "df_insert = df_sample.limit(10).toPandas()\n",
    "\n",
    "insert_statements = []\n",
    "insert_statements.append(\"-- Inserir dados de exemplo\\n\")\n",
    "insert_statements.append(\"USE datalake_local;\\nGO\\n\\n\")\n",
    "\n",
    "for _, row in df_insert.iterrows():\n",
    "    insert = f\"\"\"INSERT INTO dbo.covid19_brazil (data, estado, cidade, casos_totais, casos_novos, obitos_totais, obitos_novos, ano, mes) VALUES ('{row['data']}', '{row['estado']}', '{row['cidade']}', {row['casos_totais']}, {row['casos_novos']}, {row['obitos_totais']}, {row['obitos_novos']}, {row['ano']}, {row['mes']});\"\"\"\n",
    "    insert_statements.append(insert + \"\\n\")\n",
    "\n",
    "insert_statements.append(\"\\nGO\\n\")\n",
    "insert_statements.append(\"\\nPRINT 'Dados inseridos';\\nGO\")\n",
    "\n",
    "insert_file = \"../sql/insert_covid19_sample.sql\"\n",
    "with open(insert_file, 'w', encoding='utf-8') as f:\n",
    "    f.writelines(insert_statements)\n",
    "\n",
    "print(f\"Script INSERT salvo: {insert_file}\")\n",
    "print(f\"Total de INSERTs: {len(df_insert)}\")\n",
    "\n",
    "print(\"\\nExemplo de INSERT:\")\n",
    "print(''.join(insert_statements[:5]))\n",
    "\n",
    "# ============================================\n",
    "\n",
    "# Resumo\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESUMO DO PIPELINE ETL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nEXTRACT:\")\n",
    "print(f\"  Fonte: COVID-19 Brasil (GitHub)\")\n",
    "print(f\"  Registros originais: {df_raw.count():,}\")\n",
    "\n",
    "print(\"\\nTRANSFORM:\")\n",
    "print(f\"  Colunas: {len(df_clean.columns)}\")\n",
    "print(f\"  Registros limpos: {df_clean.count():,}\")\n",
    "\n",
    "print(\"\\nLOAD:\")\n",
    "print(f\"  CSV: {processed_file}\")\n",
    "print(f\"  Parquet: {parquet_path}\")\n",
    "print(f\"  SQL: {sql_file}\")\n",
    "print(f\"  Inserts: {insert_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Pipeline concluído\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nSpark Session ativa para análises adicionais\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd5c982-9c79-41a7-aa18-65629d401d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
